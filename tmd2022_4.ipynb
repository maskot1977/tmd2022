{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maskot1977/tmd2022/blob/DKDytdpdfBG1tpbY/tmd2022_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p39NiE6XI0cy"
      },
      "source": [
        "「AI創薬・ケモインフォマティクス入門」講義資料　（講師：小寺正明）\n",
        "\n",
        "2月15日(土)19:40～21:10 第4回「化学記述子」\n",
        "\n",
        "# Optunaによる学習結果保存のための設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neZMyA0gFiLm"
      },
      "outputs": [],
      "source": [
        "# 以下の設定は必要に応じて適宜調整してください。\n",
        "dateflag = \"0216a\"  # 解析日を記録するための変数\n",
        "MODEL_PATH = \"./drive/MyDrive/tmd2022-3/\"  # データの保存場所を指定するための変数\n",
        "learning_time_limit = 300  # １つの学習器あたりに許す最大の学習時間（秒）\n",
        "timeout_optuna = 600  # Optuna による反復計算に許す最大の学習時間（秒）\n",
        "n_trials_optuna = 10  # Optuna による反復計算の最大回数（普通は100や1000などの数字を入れる）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QN83uAeI669"
      },
      "source": [
        "# Google Colaboratory から Google Drive へのマウント"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJU8X5d0Fn4R"
      },
      "outputs": [],
      "source": [
        "# Google Colaboratory から Google Drive にマウント\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UngxAf7fFvb_"
      },
      "outputs": [],
      "source": [
        "# もしデータ保存場所がなければ作る\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    os.makedirs(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fUk1g0uJAz3"
      },
      "source": [
        "# Optuna のインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFObavK_GfAB"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08_buvRAJEHh"
      },
      "source": [
        "# RDKit のインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GzpnJy_bU8R"
      },
      "outputs": [],
      "source": [
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install -q -y -c rdkit rdkit python=3.7\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"/usr/local/lib/python3.7/site-packages/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7H-VM39gAj0"
      },
      "source": [
        "# 化合物データ取得"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW7Vb-U_gDU7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# csvからのデータ読み込み\n",
        "url = \"https://raw.githubusercontent.com/maskot1977/toydata/main/data/data_18.csv\"\n",
        "df_reg = pd.read_csv(url)\n",
        "df_reg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ko2ZXTy09qO"
      },
      "source": [
        "# 目的変数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyk48sWf08sq"
      },
      "outputs": [],
      "source": [
        "Y = df_reg[\"Melting point\"]\n",
        "Y.hist(bins=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3Ht5RHEgOef"
      },
      "source": [
        "## 回帰用データを分類用データに変換（練習のため）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypmo6pJggN8o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "df_cla = pd.DataFrame(\n",
        "    np.where(df_reg > df_reg.describe().median() * 1.8, 1, 0), columns=df_reg.columns\n",
        ")\n",
        "df_cla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ti474OxU1U0Y"
      },
      "outputs": [],
      "source": [
        "Y2 = df_cla[\"Melting point\"]\n",
        "Y2.hist(bins=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qreJv2rYJKg"
      },
      "source": [
        "# RDKit supporter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmpj76TGboXi"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/maskot1977/rdkit_supporter.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sz0nlqCkoxy"
      },
      "source": [
        "## RDKit 記述子"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eynPQyDecJ4j"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "from rdkit_supporter.descriptors import calc_descriptors\n",
        "\n",
        "rdkit_df = calc_descriptors(df_reg[\"Open Babel SMILES\"])\n",
        "display(rdkit_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiOlVNd4mHCt"
      },
      "source": [
        "## フィンガープリント\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XgPj1NIkiEr"
      },
      "outputs": [],
      "source": [
        "# rdkit_supporter で取り扱えるフィンガープリントのリスト\n",
        "from rdkit_supporter.fingerprints import Fingerprinter\n",
        "\n",
        "fingerprinter = Fingerprinter()\n",
        "fingerprinter.names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7TowU3OlZGU"
      },
      "outputs": [],
      "source": [
        "fp_type = \"ECFP2\"\n",
        "fp_df = pd.DataFrame(\n",
        "    [\n",
        "        vec\n",
        "        for vec in fingerprinter.transform(df_reg[\"Open Babel SMILES\"], fp_type=fp_type)\n",
        "    ]\n",
        ")\n",
        "fp_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soO9nM_z3ybI"
      },
      "source": [
        "# 説明変数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eddngk41m_JO"
      },
      "outputs": [],
      "source": [
        "X = fp_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz5TwhSDJfhe"
      },
      "source": [
        "# 欠損値の補間"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofMmMLgR1crS"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "model = SVR()\n",
        "model.fit(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV8h0UtIIyIX"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "imputer = KNNImputer()\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjGI8MgF1hgL"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "model = SVR()\n",
        "model.fit(X, Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvblTyeLJkIq"
      },
      "source": [
        "# データ分割"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrVdKjxjGRsu"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.33, random_state=53\n",
        ")\n",
        "X_tra, X_val, Y_tra, Y_val = train_test_split(\n",
        "    X_train, Y_train, test_size=0.5, random_state=53\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEnZ_iH13tjV"
      },
      "outputs": [],
      "source": [
        "X_tra.shape, X_val.shape, X_test.shape, Y_tra.shape, Y_val.shape, Y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldzuW1en4XmO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test, Y2_train, Y2_test = train_test_split(\n",
        "    X, Y, Y2, test_size=0.33, random_state=53\n",
        ")\n",
        "X_tra, X_val, Y_tra, Y_val, Y2_tra, Y2_val = train_test_split(\n",
        "    X_train, Y_train, Y2_train, test_size=0.5, random_state=53\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wehJMccE4ses"
      },
      "outputs": [],
      "source": [
        "Y2_tra.shape, Y2_val.shape, Y2_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRRydqZZmtGq"
      },
      "source": [
        "# 基本\n",
        "\n",
        "## 回帰問題"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIG9NR5w8nYy"
      },
      "outputs": [],
      "source": [
        "performance_record = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0KJOcCk6HvM"
      },
      "source": [
        "# LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1p7PIn_yhw5"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X, Y)\n",
        "r1o, r2o = depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "r1b, r2b = depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGx5Ejlh8mDN"
      },
      "outputs": [],
      "source": [
        "performance_record[\"LR\"] = [r1o, r1b, r2o, r2b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JU1o9Zx6Lm2"
      },
      "source": [
        "# Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci22xKvNyze7"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "model = Ridge()\n",
        "model.fit(X, Y)\n",
        "r1o, r2o = depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = Ridge()\n",
        "model.fit(X_train, Y_train)\n",
        "r1b, r2b = depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0Uc0loN86Zv"
      },
      "outputs": [],
      "source": [
        "performance_record[\"R\"] = [r1o, r1b, r2o, r2b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RXvVExq6OUA"
      },
      "source": [
        "# Lasso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSE6JbLGzHSE"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "model = Lasso()\n",
        "model.fit(X, Y)\n",
        "r1o, r2o = depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = Lasso()\n",
        "model.fit(X_train, Y_train)\n",
        "r1b, r2b = depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9n397vq9J5K"
      },
      "outputs": [],
      "source": [
        "performance_record[\"L\"] = [r1o, r1b, r2o, r2b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwAJERCa6RCg"
      },
      "source": [
        "# ElasticNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Uq-lkhwzHOt"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "model = ElasticNet()\n",
        "model.fit(X, Y)\n",
        "r1o, r2o = depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = ElasticNet()\n",
        "model.fit(X_train, Y_train)\n",
        "r1b, r2b = depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grFFL0B39UXW"
      },
      "outputs": [],
      "source": [
        "performance_record[\"EN\"] = [r1o, r1b, r2o, r2b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1M4FblR6V8b"
      },
      "source": [
        "# BayesianRidge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q11PujrDzHMp"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "\n",
        "model = BayesianRidge()\n",
        "model.fit(X, Y)\n",
        "r1o, r2o = depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = BayesianRidge()\n",
        "model.fit(X_train, Y_train)\n",
        "r1b, r2b = depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwYzp50z9jAH"
      },
      "outputs": [],
      "source": [
        "performance_record[\"BR\"] = [r1o, r1b, r2o, r2b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl9t5-hT6afM"
      },
      "source": [
        "# SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3cSNghEqvZj"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "model = SVR()\n",
        "model.fit(X, Y)\n",
        "r1o, r2o = depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = SVR()\n",
        "model.fit(X_train, Y_train)\n",
        "r1b, r2b = depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj-sIajk9qfn"
      },
      "outputs": [],
      "source": [
        "performance_record[\"SVR\"] = [r1o, r1b, r2o, r2b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYUAun8I6fgz"
      },
      "source": [
        "# KNeighborsRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eKphWl04yHN"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "model = KNeighborsRegressor()\n",
        "model.fit(X, Y)\n",
        "r1o, r2o = depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = KNeighborsRegressor()\n",
        "model.fit(X_train, Y_train)\n",
        "r1b, r2b = depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzj8X6ds95LP"
      },
      "outputs": [],
      "source": [
        "performance_record[\"KN\"] = [r1o, r1b, r2o, r2b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQrVC07V6j4F"
      },
      "source": [
        "# GaussianProcessRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSCc9lGp0iWS"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "\n",
        "model = GaussianProcessRegressor()\n",
        "model.fit(X, Y)\n",
        "r1o, r2o = depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = GaussianProcessRegressor()\n",
        "model.fit(X_train, Y_train)\n",
        "r1b, r2b = depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNtpmDqh-BMA"
      },
      "outputs": [],
      "source": [
        "performance_record[\"GP\"] = [r1o, r1b, r2o, r2b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ohy7nsDX6q2G"
      },
      "source": [
        "# PLSRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mU-xxWl03s4"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "\n",
        "model = PLSRegression()\n",
        "model.fit(X, Y)\n",
        "r1o, r2o = depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = PLSRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "r1b, r2b = depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_h_QRBR-MuS"
      },
      "outputs": [],
      "source": [
        "performance_record[\"PLS\"] = [r1o, r1b, r2o, r2b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-dcGGqu6uK6"
      },
      "source": [
        "# DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcHJSW8z3gMk"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(X, Y)\n",
        "r1o, r2o = depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(X_train, Y_train)\n",
        "r1b, r2b = depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKzuiDHY-VBT"
      },
      "outputs": [],
      "source": [
        "performance_record[\"DT\"] = [r1o, r1b, r2o, r2b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5j8Slxa6xsY"
      },
      "source": [
        "# RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3R9kHy24Mi3"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X, Y)\n",
        "r1o, r2o = depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X_train, Y_train)\n",
        "r1b, r2b = depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0COZlPlW-cqC"
      },
      "outputs": [],
      "source": [
        "performance_record[\"RF\"] = [r1o, r1b, r2o, r2b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPwkfeDe61Ev"
      },
      "source": [
        "# AdaBoostRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6DsRAlk4LTl"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "\n",
        "model = AdaBoostRegressor()\n",
        "model.fit(X, Y)\n",
        "r1o, r2o = depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = AdaBoostRegressor()\n",
        "model.fit(X_train, Y_train)\n",
        "r1b, r2b = depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ms-ogNzO-ry3"
      },
      "outputs": [],
      "source": [
        "performance_record[\"AB\"] = [r1o, r1b, r2o, r2b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bCKpesD64VZ"
      },
      "source": [
        "# ExtraTreesRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QaBSZPo4WPJ"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "model = ExtraTreesRegressor()\n",
        "model.fit(X, Y)\n",
        "r1o, r2o = depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = ExtraTreesRegressor()\n",
        "model.fit(X_train, Y_train)\n",
        "r1b, r2b = depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_fWfyMU-0Jx"
      },
      "outputs": [],
      "source": [
        "performance_record[\"ET\"] = [r1o, r1b, r2o, r2b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K1c2cq-67hT"
      },
      "source": [
        "# HistGradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTIxI-CM43oQ"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "\n",
        "model = HistGradientBoostingRegressor()\n",
        "model.fit(X, Y)\n",
        "r1o, r2o = depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = HistGradientBoostingRegressor()\n",
        "model.fit(X_train, Y_train)\n",
        "r1b, r2b = depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_kYMy4c-4z-"
      },
      "outputs": [],
      "source": [
        "performance_record[\"GB\"] = [r1o, r1b, r2o, r2b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odjrZy5t6-rP"
      },
      "source": [
        "# MLPRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvPgEPcd4-k-"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "model = MLPRegressor()\n",
        "model.fit(X, Y)\n",
        "r1o, r2o = depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = MLPRegressor()\n",
        "model.fit(X_train, Y_train)\n",
        "r1b, r2b = depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxnPEPAS-9_u"
      },
      "outputs": [],
      "source": [
        "performance_record[\"MLP\"] = [r1o, r1b, r2o, r2b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIHyhaf97Bz9"
      },
      "source": [
        "# 回帰手法間の比較"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Xp-3j_MAN13"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(14, 8))\n",
        "for name, v in performance_record.items():\n",
        "    axes[0].scatter(v[0], v[1], label=name)\n",
        "    axes[0].text(v[0], v[1], name, alpha=0.6)\n",
        "    axes[1].scatter(v[0], v[2], label=name)\n",
        "    axes[1].text(v[0], v[2], name, alpha=0.6)\n",
        "    axes[1].scatter(v[1], v[3], label=name)\n",
        "    axes[1].text(v[1], v[3], name, alpha=0.6)\n",
        "    axes[2].scatter(v[2], v[3], label=name)\n",
        "    axes[2].text(v[2], v[3], name, alpha=0.6)\n",
        "axes[0].set_xlabel(\"R (all data)\")\n",
        "axes[0].set_ylabel(\"R (split data)\")\n",
        "axes[0].grid()\n",
        "axes[1].set_xlabel(\"R\")\n",
        "axes[1].set_ylabel(\"R2\")\n",
        "axes[1].grid()\n",
        "axes[2].set_xlabel(\"R2 (all data)\")\n",
        "axes[2].set_ylabel(\"R2 (split data)\")\n",
        "axes[2].grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZNEyaBhtm_N"
      },
      "source": [
        "# 分類問題"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1zJ3EfxGsV4"
      },
      "outputs": [],
      "source": [
        "performance_record = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMu8Ahe77Pbh"
      },
      "source": [
        "## LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gj5go4k7QKSY"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIS_o0I8G6QP"
      },
      "outputs": [],
      "source": [
        "performance_record[\"LR\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLWZ25lM7Z9d"
      },
      "source": [
        "## PassiveAggressiveClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGo5k2dCQVpM"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "\n",
        "model = PassiveAggressiveClassifier()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = PassiveAggressiveClassifier()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ0dTnEtHIae"
      },
      "outputs": [],
      "source": [
        "performance_record[\"PA\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOZHKVec7c4-"
      },
      "source": [
        "## Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFHOt6EEQ22f"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "model = Perceptron()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = Perceptron()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XP5bmnMBHQ47"
      },
      "outputs": [],
      "source": [
        "performance_record[\"P\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsLilF7A7gsX"
      },
      "source": [
        "## SGDClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioal93WbQ-8Y"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "model = SGDClassifier()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = SGDClassifier()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDdU0r2bHYJ_"
      },
      "outputs": [],
      "source": [
        "performance_record[\"SGD\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R08uZpLM7jYH"
      },
      "source": [
        "## RidgeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps0uPuAmPxoe"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "model = RidgeClassifier()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = RidgeClassifier()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E43AaSHYHgRv"
      },
      "outputs": [],
      "source": [
        "performance_record[\"R\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSF6JiR07mGb"
      },
      "source": [
        "## LinearDiscriminantAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txsbWBOYRoWg"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "model = LinearDiscriminantAnalysis()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = LinearDiscriminantAnalysis()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxOdin3EHoXh"
      },
      "outputs": [],
      "source": [
        "performance_record[\"LDA\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_zsmtIw7oyD"
      },
      "source": [
        "## QuadraticDiscriminantAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrHmnN91R4Qn"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "model = QuadraticDiscriminantAnalysis()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = QuadraticDiscriminantAnalysis()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPXVfh7JHxbx"
      },
      "outputs": [],
      "source": [
        "performance_record[\"QDA\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Auc8bMv7tdt"
      },
      "source": [
        "## SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-neXagDUQIQc"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = SVC()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25D99_EIH5Vd"
      },
      "outputs": [],
      "source": [
        "performance_record[\"SVC\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fv2CSbd47wi7"
      },
      "source": [
        "## KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6ppvc6xQvo9"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "model = KNeighborsClassifier()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = KNeighborsClassifier()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws1tOMIgIBOj"
      },
      "outputs": [],
      "source": [
        "performance_record[\"KN\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riRaORTg7zWQ"
      },
      "source": [
        "## GaussianProcessClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1R2LRDHSg99"
      },
      "outputs": [],
      "source": [
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "\n",
        "model = GaussianProcessClassifier()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = GaussianProcessClassifier()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ap9ZIOLfIJa5"
      },
      "outputs": [],
      "source": [
        "performance_record[\"GP\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elkDk3l872SB"
      },
      "source": [
        "## GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrSjgM-US4KP"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JETSuQjDITuQ"
      },
      "outputs": [],
      "source": [
        "performance_record[\"GNB\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n9t1GRF75HS"
      },
      "source": [
        "## BernoulliNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6bbYcsmTJI-"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "model = BernoulliNB()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = BernoulliNB()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ta2RDrveIcM3"
      },
      "outputs": [],
      "source": [
        "performance_record[\"BNB\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzZXR7ir78Bd"
      },
      "source": [
        "## DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrM5iZdETgPn"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtTtL-FlIjJj"
      },
      "outputs": [],
      "source": [
        "performance_record[\"DT\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMXEjlYk7-7_"
      },
      "source": [
        "## RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er58ClHhQkvl"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ6duc4zIo8e"
      },
      "outputs": [],
      "source": [
        "performance_record[\"RF\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1qcslgA8BjZ"
      },
      "source": [
        "## AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NunEtLjnT3_f"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "model = AdaBoostClassifier()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = AdaBoostClassifier()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmiKsau5Iu88"
      },
      "outputs": [],
      "source": [
        "performance_record[\"AB\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKiScPSk8ENJ"
      },
      "source": [
        "## ExtraTreesClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPo6gpyGUIiv"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iFF7rgcI1Vj"
      },
      "outputs": [],
      "source": [
        "performance_record[\"ET\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPx2FuXi8HrK"
      },
      "source": [
        "## HistGradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V09kEpItQ8ZW"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "model = HistGradientBoostingClassifier()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = HistGradientBoostingClassifier()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9af2FZ3I7v0"
      },
      "outputs": [],
      "source": [
        "performance_record[\"GB\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzOMF-4e8Kqy"
      },
      "source": [
        "## MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR6xqp8jRH1T"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "model = MLPClassifier()\n",
        "model.fit(X, Y2)\n",
        "po, ro = depict.classification_metrics(model, X, Y2)\n",
        "\n",
        "model = MLPClassifier()\n",
        "model.fit(X_train, Y2_train)\n",
        "pb, rb = depict.classification_metrics(model, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SGuWWsZJCkU"
      },
      "outputs": [],
      "source": [
        "performance_record[\"MLP\"] = [po, pb, ro, rb]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs9TI1VM8NEd"
      },
      "source": [
        "## 分類手法間の比較"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRQ5VeF-JLGo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(14, 8))\n",
        "for name, v in performance_record.items():\n",
        "    axes[0].scatter(v[0], v[1], label=name)\n",
        "    axes[0].text(v[0], v[1], name, alpha=0.6)\n",
        "\n",
        "    axes[1].scatter(v[2], v[0], label=name)\n",
        "    axes[1].text(v[2], v[0], name + \"(a)\", alpha=0.6)\n",
        "    axes[1].scatter(v[3], v[1], label=name)\n",
        "    axes[1].text(v[3], v[1], name + \"(s)\", alpha=0.6)\n",
        "\n",
        "    axes[2].scatter(v[2], v[3], label=name)\n",
        "    axes[2].text(v[2], v[3], name, alpha=0.6)\n",
        "axes[0].set_xlabel(\"Precision (all data)\")\n",
        "axes[0].set_ylabel(\"Precision (split data)\")\n",
        "axes[0].grid()\n",
        "axes[1].set_xlabel(\"Recall\")\n",
        "axes[1].set_ylabel(\"Precision\")\n",
        "axes[1].grid()\n",
        "axes[2].set_xlabel(\"Recall (all data)\")\n",
        "axes[2].set_ylabel(\"Recall (split data)\")\n",
        "axes[2].grid()\n",
        "axes[0].set_aspect(1.0)\n",
        "axes[1].set_aspect(1.0)\n",
        "axes[2].set_aspect(1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6olp3J4G8Wu4"
      },
      "source": [
        "# Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AxrF0mXY3f_"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "model = SVR()\n",
        "model.fit(X, Y)\n",
        "depict.regression_metrics(model, X, Y)\n",
        "\n",
        "model = SVR()\n",
        "model.fit(X_train, Y_train)\n",
        "depict.regression_metrics(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n61C1p4_8cab"
      },
      "source": [
        "## GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO6BXENxjTqm"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = dict(\n",
        "    {\n",
        "        \"C\": [1, 10],\n",
        "        \"kernel\": [\"poly\", \"rbf\"],\n",
        "        \"gamma\": [\"auto\", \"scale\"],\n",
        "        \"degree\": [1, 3],\n",
        "        \"max_iter\": [530000],\n",
        "    }\n",
        ")\n",
        "model = GridSearchCV(SVR(), parameters, cv=2, n_jobs=-1, verbose=3)\n",
        "model.fit(X_train, Y_train)\n",
        "depict.regression_metrics(model, X_test, Y_test)\n",
        "model.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BninWpC08e0d"
      },
      "source": [
        "## HalvingGridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXOqgZDiktwJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "\n",
        "parameters = dict(\n",
        "    {\n",
        "        \"C\": [1, 10],\n",
        "        \"kernel\": [\"poly\", \"rbf\"],\n",
        "        \"gamma\": [\"auto\", \"scale\"],\n",
        "        \"degree\": [1, 3],\n",
        "        \"max_iter\": [530000],\n",
        "    }\n",
        ")\n",
        "model = HalvingGridSearchCV(SVR(), parameters, cv=2, n_jobs=-1, verbose=3)\n",
        "model.fit(X_train, Y_train)\n",
        "depict.regression_metrics(model, X_test, Y_test)\n",
        "model.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv6NqU0j8g7A"
      },
      "source": [
        "## RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSUYgzDiE_kb"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import randint, uniform\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "parameters = dict(\n",
        "    {\n",
        "        \"C\": uniform(1e-4, 1e4),\n",
        "        \"kernel\": [\"poly\", \"rbf\"],\n",
        "        \"gamma\": [\"auto\", \"scale\"],\n",
        "        \"degree\": randint(1, 3),\n",
        "        \"max_iter\": [530000],\n",
        "    }\n",
        ")\n",
        "model = RandomizedSearchCV(SVR(), parameters, cv=2, n_jobs=-1, verbose=3)\n",
        "model.fit(X_train, Y_train)\n",
        "depict.regression_metrics(model, X_test, Y_test)\n",
        "model.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3Uqv_zp8jLQ"
      },
      "source": [
        "## HalvingRandomSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kj_3ZOP8mGR_"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import randint, uniform\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingRandomSearchCV\n",
        "\n",
        "parameters = dict(\n",
        "    {\n",
        "        \"C\": uniform(1e-4, 1e4),\n",
        "        \"kernel\": [\"poly\", \"rbf\"],\n",
        "        \"gamma\": [\"auto\", \"scale\"],\n",
        "        \"degree\": randint(1, 3),\n",
        "        \"max_iter\": [530000],\n",
        "    }\n",
        ")\n",
        "model = HalvingRandomSearchCV(SVR(), parameters, cv=2, n_jobs=-1, verbose=3)\n",
        "model.fit(X_train, Y_train)\n",
        "depict.regression_metrics(model, X_test, Y_test)\n",
        "model.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5p3p_p68mmx"
      },
      "source": [
        "# Optunaによる多目的最適化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFxdjbjMFWFX"
      },
      "outputs": [],
      "source": [
        "from functools import wraps\n",
        "\n",
        "\n",
        "# 学習に時間がかかりすぎる場合に強制終了するための方法\n",
        "def on_timeout(limit, handler, hint=None):\n",
        "    def notify_handler(signum, frame):\n",
        "        handler(\n",
        "            \"'%s' terminated since it did not finish in %d seconds.\" % (hint, limit)\n",
        "        )\n",
        "\n",
        "    def __decorator(function):\n",
        "        def __wrapper(*args, **kwargs):\n",
        "            import signal\n",
        "\n",
        "            signal.signal(signal.SIGALRM, notify_handler)\n",
        "            signal.alarm(limit)\n",
        "            result = function(*args, **kwargs)\n",
        "            signal.alarm(0)\n",
        "            return result\n",
        "\n",
        "        return wraps(function)(__wrapper)\n",
        "\n",
        "    return __decorator\n",
        "\n",
        "\n",
        "def handler_func(msg):\n",
        "    print(msg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnIn9wJBFZ2X"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef, r2_score\n",
        "\n",
        "\n",
        "# Optunaでチューニングするための基本クラス\n",
        "class BestTune:\n",
        "    def __init__(self, x_train, x_valid, t_train, t_valid, task=\"regressor\"):\n",
        "        # 訓練データを格納\n",
        "        self.x_train = x_train\n",
        "        self.t_train = t_train\n",
        "\n",
        "        # 検証データを格納\n",
        "        self.x_valid = x_valid\n",
        "        self.t_valid = t_valid\n",
        "\n",
        "        # regressor か classifier か\n",
        "        self.task = task\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            self.measure = r2_score\n",
        "        else:\n",
        "            self.measure = matthews_corrcoef\n",
        "\n",
        "        # ベストモデルとスコアを格納\n",
        "        self.best_score = None\n",
        "        self.best_estimator_ = None\n",
        "\n",
        "    def get_params(self, trial):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_base_model(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @on_timeout(limit=learning_time_limit, handler=handler_func, hint=u\"BestTune\")\n",
        "    def fit(self, trial):\n",
        "        model = self.get_base_model()(**self.get_params(trial))\n",
        "        model.fit(self.x_train, self.t_train)\n",
        "        return model\n",
        "\n",
        "    def __call__(self, trial):\n",
        "        start_time = time.perf_counter()\n",
        "        # 教師データで学習\n",
        "        model = self.fit(trial)\n",
        "\n",
        "        # 検証データの予測性能を評価\n",
        "        score = self.measure(model.predict(self.x_valid), self.t_valid)\n",
        "        end_time = time.perf_counter()\n",
        "\n",
        "        # ベストスコアが出れば、そのベストモデルを記録\n",
        "        if self.best_estimator_ is None or self.best_score < score:\n",
        "            self.best_score = score\n",
        "            self.best_estimator_ = copy.deepcopy(model)\n",
        "\n",
        "        # 多目的最適化\n",
        "        return max(-1, score), end_time - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ33lIAOF5Yi"
      },
      "outputs": [],
      "source": [
        "# Support Vector Machine\n",
        "from sklearn.svm import SVC, SVR\n",
        "\n",
        "\n",
        "class tune_SVM(BestTune):\n",
        "    def get_base_model(self):\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            return SVR\n",
        "        else:\n",
        "            return SVC\n",
        "\n",
        "    def default_params(self):\n",
        "        params = {\n",
        "            \"C\": 1.0,\n",
        "            \"gamma\": 1 / len(self.x_train.shape[1]),\n",
        "        }\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            params[\"epsilon\"] = 0.1\n",
        "        else:\n",
        "            params[\"class_weight\"] = None\n",
        "        return params\n",
        "\n",
        "    def get_params(self, trial):\n",
        "        # チューニングしたいパラメータの範囲を設定\n",
        "        params = {}\n",
        "        params[\"C\"] = trial.suggest_float(\"C\", 1e-10, 1e10, log=True)\n",
        "        params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-10, 1e10, log=True)\n",
        "        params[\"max_iter\"] = 530000\n",
        "\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            params[\"epsilon\"] = trial.suggest_float(\"epsilon\", 1e-10, 1e10, log=True)\n",
        "        else:\n",
        "            params[\"class_weight\"] = trial.suggest_categorical(\n",
        "                \"class_weight\", [\"balanced\", None]\n",
        "            )\n",
        "        return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pd2eNs4F8Wa"
      },
      "outputs": [],
      "source": [
        "# K-Neighbors\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "\n",
        "\n",
        "class tune_KN(BestTune):\n",
        "    def get_base_model(self):\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            return KNeighborsRegressor\n",
        "        else:\n",
        "            return KNeighborsClassifier\n",
        "\n",
        "    def default_params(self):\n",
        "        params = {\"algorithm\": \"brute\", \"n_neighbors\": 5, \"weights\": \"uniform\"}\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            pass\n",
        "        else:\n",
        "            pass\n",
        "        return params\n",
        "\n",
        "    def get_params(self, trial):\n",
        "        params = {}\n",
        "        params[\"algorithm\"] = trial.suggest_categorical(\n",
        "            \"algorithm\", [\"ball_tree\", \"kd_tree\", \"brute\"]\n",
        "        )\n",
        "        params[\"n_neighbors\"] = trial.suggest_int(\"n_neighbors\", 1, 10)\n",
        "        params[\"weights\"] = trial.suggest_categorical(\n",
        "            \"weights\", [\"uniform\", \"distance\"]\n",
        "        )\n",
        "        return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zElA3UE3GBcl"
      },
      "outputs": [],
      "source": [
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "\n",
        "\n",
        "class tune_DT(BestTune):\n",
        "    def get_base_model(self):\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            return DecisionTreeRegressor\n",
        "        else:\n",
        "            return DecisionTreeClassifier\n",
        "\n",
        "    def default_params(self):\n",
        "        params = {\n",
        "            \"max_depth\": 100,\n",
        "            \"min_samples_leaf\": 2,\n",
        "        }\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            params[\"criterion\"] = \"squared_error\"\n",
        "        else:\n",
        "            params[\"gini\"] = \"squared_error\"\n",
        "        return params\n",
        "\n",
        "    def get_params(self, trial):\n",
        "        params = {}\n",
        "        params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 100)\n",
        "        params[\"min_samples_leaf\"] = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            params[\"criterion\"] = trial.suggest_categorical(\n",
        "                \"criterion\", [\"squared_error\", \"friedman_mse\", \"absolute_error\"]\n",
        "            )\n",
        "        else:\n",
        "            params[\"criterion\"] = trial.suggest_categorical(\n",
        "                \"criterion\", [\"gini\", \"entropy\"]  # , \"log_loss\"]\n",
        "            )\n",
        "        return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARzovNijGFZd"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "\n",
        "\n",
        "class tune_RF(BestTune):\n",
        "    def get_base_model(self):\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            return RandomForestRegressor\n",
        "        else:\n",
        "            return RandomForestClassifier\n",
        "\n",
        "    def default_params(self):\n",
        "        params = {\n",
        "            \"max_depth\": 100,\n",
        "            \"min_samples_leaf\": 1,\n",
        "        }\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            params[\"criterion\"] = \"squared_error\"\n",
        "        else:\n",
        "            params[\"criterion\"] = \"gini\"\n",
        "        return params\n",
        "\n",
        "    def get_params(self, trial):\n",
        "        params = {}\n",
        "        params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 100)\n",
        "        params[\"min_samples_leaf\"] = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            params[\"criterion\"] = trial.suggest_categorical(\n",
        "                \"criterion\", [\"squared_error\", \"friedman_mse\", \"absolute_error\"]\n",
        "            )\n",
        "        else:\n",
        "            params[\"criterion\"] = trial.suggest_categorical(\n",
        "                \"criterion\", [\"gini\", \"entropy\"]  # , \"log_loss\"]\n",
        "            )\n",
        "        return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LuRIy5rGIoU"
      },
      "outputs": [],
      "source": [
        "# ExtraTrees\n",
        "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
        "\n",
        "\n",
        "class tune_ET(BestTune):\n",
        "    def get_base_model(self):\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            return ExtraTreesRegressor\n",
        "        else:\n",
        "            return ExtraTreesClassifier\n",
        "\n",
        "    def default_params(self):\n",
        "        params = {\n",
        "            \"max_depth\": 100,\n",
        "            \"min_samples_leaf\": 1,\n",
        "        }\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            params[\"criterion\"] = \"squared_error\"\n",
        "        else:\n",
        "            params[\"criterion\"] = \"gini\"\n",
        "        return params\n",
        "\n",
        "    def get_params(self, trial):\n",
        "        params = {}\n",
        "        params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 100)\n",
        "        params[\"min_samples_leaf\"] = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            params[\"criterion\"] = trial.suggest_categorical(\n",
        "                \"criterion\", [\"squared_error\", \"friedman_mse\", \"absolute_error\"]\n",
        "            )\n",
        "        else:\n",
        "            params[\"criterion\"] = trial.suggest_categorical(\n",
        "                \"criterion\", [\"gini\", \"entropy\"]  # , \"log_loss\"]\n",
        "            )\n",
        "        return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcYyFHTuGLt4"
      },
      "outputs": [],
      "source": [
        "# GradientBoosting\n",
        "\n",
        "from sklearn.ensemble import (\n",
        "    HistGradientBoostingClassifier,\n",
        "    HistGradientBoostingRegressor,\n",
        ")\n",
        "\n",
        "\n",
        "class tune_GB(BestTune):\n",
        "    def get_base_model(self):\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            return HistGradientBoostingRegressor\n",
        "        else:\n",
        "            return HistGradientBoostingClassifier\n",
        "\n",
        "    def default_params(self):\n",
        "        params = {\n",
        "            \"max_depth\": 100,\n",
        "            \"min_samples_leaf\": 10,\n",
        "        }\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            params[\"loss\"] = \"squared_error\"\n",
        "        else:\n",
        "            params[\"loss\"] = \"log_loss\"\n",
        "        return params\n",
        "\n",
        "    def get_params(self, trial):\n",
        "        params = {}\n",
        "        params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 100)\n",
        "        params[\"min_samples_leaf\"] = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            params[\"loss\"] = trial.suggest_categorical(\n",
        "                \"loss\", [\"squared_error\", \"absolute_error\"]\n",
        "            )\n",
        "        else:\n",
        "            params[\"loss\"] = trial.suggest_categorical(\n",
        "                \"loss\", [\"auto\", \"binary_crossentropy\", \"log_loss\"]\n",
        "            )\n",
        "        return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvWaNQSPGO94"
      },
      "outputs": [],
      "source": [
        "# Multi-Layer Perceptron\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "\n",
        "\n",
        "class tune_MLP(BestTune):\n",
        "    def get_base_model(self):\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            return MLPRegressor\n",
        "        else:\n",
        "            return MLPClassifier\n",
        "\n",
        "    def default_params(self):\n",
        "        params = {\n",
        "            \"n_layer\": 1,\n",
        "            \"in_neuron\": 100,\n",
        "            \"mid_neuron\": 100,\n",
        "            \"out_neuron\": 100,\n",
        "            \"activation\": \"relu\",\n",
        "            \"learning_rate\": \"constant\",\n",
        "            \"batch_size\": min(200, self.x_train.shape[0]),\n",
        "            \"early_stopping\": False,\n",
        "            \"alpha\": 0.0001,\n",
        "            \"learning_rate_init\": 0.001,\n",
        "            \"max_iter\": 530000,\n",
        "        }\n",
        "        if self.task[0] == \"r\" or self.task[0] == \"R\":\n",
        "            pass\n",
        "        else:\n",
        "            pass\n",
        "        return params\n",
        "\n",
        "    def get_params(self, trial):\n",
        "        params = {}\n",
        "        n_layer = trial.suggest_int(\"n_layer\", 1, 10)\n",
        "        in_neuron = trial.suggest_int(\"in_neuron\", 1, 200)\n",
        "        mid_neuron = trial.suggest_int(\"mid_neuron\", 1, 200)\n",
        "        out_neuron = trial.suggest_int(\"out_neuron\", 1, 200)\n",
        "        params[\"hidden_layer_sizes\"] = (\n",
        "            [in_neuron] + [mid_neuron] * n_layer + [out_neuron]\n",
        "        )\n",
        "        params[\"activation\"] = trial.suggest_categorical(\n",
        "            \"activation\", [\"logistic\", \"tanh\", \"relu\"]\n",
        "        )\n",
        "        params[\"learning_rate\"] = trial.suggest_categorical(\n",
        "            \"learning_rate\", [\"constant\", \"invscaling\", \"adaptive\"]\n",
        "        )\n",
        "        params[\"batch_size\"] = trial.suggest_int(\n",
        "            \"batch_size\",\n",
        "            min(100, int(self.x_train.shape[0] / 2)),\n",
        "            max(200, int(self.x_train.shape[0])),\n",
        "        )\n",
        "        # params[\"solver\"] = trial.suggest_categorical(\n",
        "        #    \"solver\", [\"lbfgs\", \"adam\"]\n",
        "        # )\n",
        "        params[\"early_stopping\"] = trial.suggest_categorical(\n",
        "            \"early_stopping\", [True, False]\n",
        "        )\n",
        "        params[\"alpha\"] = trial.suggest_float(\"alpha\", 1e-6, 1e-2, log=True)\n",
        "        params[\"learning_rate_init\"] = trial.suggest_float(\n",
        "            \"learning_rate_init\", 1e-3, 1e-2, log=True\n",
        "        )\n",
        "        params[\"max_iter\"] = trial.suggest_int(\"max_iter\", 200, 530000)\n",
        "        return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFsu6oW0GT2N"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "\n",
        "# Optuna で学習を繰り返し、学習履歴を保存する\n",
        "def train(\n",
        "    study_name,\n",
        "    tune_model,\n",
        "    timeout=timeout_optuna,\n",
        "    n_trials=n_trials_optuna,\n",
        "    show_progress_bar=True,\n",
        "):\n",
        "    import warnings\n",
        "\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    optuna.logging.set_verbosity(optuna.logging.WARN)\n",
        "\n",
        "    # 学習環境を立ち上げる\n",
        "    study = optuna.create_study(\n",
        "        study_name=study_name,\n",
        "        storage=\"sqlite:///\" + study_name + \".sql\",\n",
        "        load_if_exists=True,\n",
        "        directions=[\"maximize\", \"minimize\"],\n",
        "        sampler=optuna.samplers.NSGAIISampler(seed=2),\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        study.enqueue_trial(study.best_trial.params)\n",
        "    except:\n",
        "        try:\n",
        "            study.enqueue_trial(tune_model.default_params())\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # 学習する\n",
        "    study.optimize(\n",
        "        tune_model,\n",
        "        timeout=timeout,\n",
        "        n_trials=n_trials,\n",
        "        show_progress_bar=show_progress_bar,\n",
        "    )\n",
        "    return tune_model, study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84oqXFErOCs5"
      },
      "source": [
        "# SVM (regressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD7d_ly1Gy8W"
      },
      "outputs": [],
      "source": [
        "strage_name = \"SVR_{}\".format(dateflag)\n",
        "overfit, overstudy = train(\n",
        "    \"{}{}_overfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_SVM(X_train, X_train, Y_train, Y_train, task=\"regressor\"),\n",
        ")\n",
        "bestfit, beststudy = train(\n",
        "    \"{}{}_bestfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_SVM(X_tra, X_val, Y_tra, Y_val, task=\"regressor\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6lHUmsShh4a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = overstudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHyiYH3hkSy6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = beststudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ebt4XwHQG77a"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "\n",
        "print(overfit.best_estimator_)\n",
        "depict.regression_metrics(overfit.best_estimator_, X_test, Y_test)\n",
        "print(bestfit.best_estimator_)\n",
        "depict.regression_metrics(bestfit.best_estimator_, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSsvWmRm54ey"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDBdrKKJlP7W"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37mX48Ec5eWJ"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4oAK0_K0mci"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyMBJsKxOGVI"
      },
      "source": [
        "# SVM (classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXVX6fanLycD"
      },
      "outputs": [],
      "source": [
        "strage_name = \"SVC_{}\".format(dateflag)\n",
        "overfit, overstudy = train(\n",
        "    \"{}{}_overfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_SVM(X_train, X_train, Y2_train, Y2_train, task=\"classifier\"),\n",
        ")\n",
        "bestfit, beststudy = train(\n",
        "    \"{}{}_bestfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_SVM(X_tra, X_val, Y2_tra, Y2_val, task=\"classifier\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puIA0AyNk_ke"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = overstudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unAhfvx5lApD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = beststudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POnZ-8RRMYnD"
      },
      "outputs": [],
      "source": [
        "print(overfit.best_estimator_)\n",
        "depict.classification_metrics(overfit.best_estimator_, X_test, Y2_test)\n",
        "print(bestfit.best_estimator_)\n",
        "depict.classification_metrics(bestfit.best_estimator_, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwVu4GCFORst"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWLk0IMtOURk"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD8qYsap_DIW"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8HDh82R_NBq"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ktls164xPdsc"
      },
      "source": [
        "# K-Neighbors (regressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbcDR-zKmIoQ"
      },
      "outputs": [],
      "source": [
        "strage_name = \"KNR_{}\".format(dateflag)\n",
        "overfit, overstudy = train(\n",
        "    \"{}{}_overfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_KN(X_train, X_train, Y_train, Y_train, task=\"regressor\"),\n",
        ")\n",
        "bestfit, beststudy = train(\n",
        "    \"{}{}_bestfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_KN(X_tra, X_val, Y_tra, Y_val, task=\"regressor\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjuNobqDlZNI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = overstudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFEtWZ_JlaKH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = beststudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BS0Or36b4Ojq"
      },
      "outputs": [],
      "source": [
        "print(overfit.best_estimator_)\n",
        "depict.regression_metrics(overfit.best_estimator_, X_test, Y_test)\n",
        "print(bestfit.best_estimator_)\n",
        "depict.regression_metrics(bestfit.best_estimator_, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkl2tKoE5mBk"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-aNUpQT5rHQ"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2lAhGhJCrVO"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1F3DjFXCxdm"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuPgJd1LP0Se"
      },
      "source": [
        "# K-Neighbors (classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXxRzrPSP1G3"
      },
      "outputs": [],
      "source": [
        "strage_name = \"KNC_{}\".format(dateflag)\n",
        "overfit, overstudy = train(\n",
        "    \"{}{}_overfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_KN(X_train, X_train, Y2_train, Y2_train, task=\"classifier\"),\n",
        ")\n",
        "bestfit, beststudy = train(\n",
        "    \"{}{}_bestfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_KN(X_tra, X_val, Y2_tra, Y2_val, task=\"classifier\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKlDx44-l5J8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = overstudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3yASxhdl6B4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = beststudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cGr5JBTQLvC"
      },
      "outputs": [],
      "source": [
        "print(overfit.best_estimator_)\n",
        "depict.classification_metrics(overfit.best_estimator_, X_test, Y2_test)\n",
        "print(bestfit.best_estimator_)\n",
        "depict.classification_metrics(bestfit.best_estimator_, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9P2VKBGQVVX"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0_5Xy80QYAf"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53RQ4pD5HPGK"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8adlE7QHR0a"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBajwcuMP0Lf"
      },
      "source": [
        "# Decision Tree (regressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l9-Ic_P5ujy"
      },
      "outputs": [],
      "source": [
        "strage_name = \"DTR_{}\".format(dateflag)\n",
        "overfit, overstudy = train(\n",
        "    \"{}{}_overfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_DT(X_train, X_train, Y_train, Y_train, task=\"regressor\"),\n",
        ")\n",
        "bestfit, beststudy = train(\n",
        "    \"{}{}_bestfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_DT(X_tra, X_val, Y_tra, Y_val, task=\"regressor\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOsVwvu6mPpe"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = overstudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziT2eNSFmQZ3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = beststudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-eDO70355Tn"
      },
      "outputs": [],
      "source": [
        "print(overfit.best_estimator_)\n",
        "depict.regression_metrics(overfit.best_estimator_, X_test, Y_test)\n",
        "print(bestfit.best_estimator_)\n",
        "depict.regression_metrics(bestfit.best_estimator_, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yodwvj3u8WRM"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y15XW3ix8ajD"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5-u5a0SIYiy"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMwoacc8IcRV"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VCoazXVTih0"
      },
      "source": [
        "# Decision Tree (classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRJhfY8aTmrQ"
      },
      "outputs": [],
      "source": [
        "strage_name = \"DTC_{}\".format(dateflag)\n",
        "overfit, overstudy = train(\n",
        "    \"{}{}_overfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_DT(X_train, X_train, Y2_train, Y2_train, task=\"classifier\"),\n",
        ")\n",
        "bestfit, beststudy = train(\n",
        "    \"{}{}_bestfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_DT(X_tra, X_val, Y2_tra, Y2_val, task=\"classifier\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMlfQKBTmd6h"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = overstudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhS3ihHnmer7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = beststudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk0SUA98Tmnm"
      },
      "outputs": [],
      "source": [
        "print(overfit.best_estimator_)\n",
        "depict.classification_metrics(overfit.best_estimator_, X_test, Y2_test)\n",
        "print(bestfit.best_estimator_)\n",
        "depict.classification_metrics(bestfit.best_estimator_, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uogt-DIvTmke"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zY2jhb8VTmgz"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_kUEfgBJSfr"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c7HSV7sJYMP"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wFxPfxGbJL9"
      },
      "source": [
        "# Random Forest (regressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a12vrzkG8d-U"
      },
      "outputs": [],
      "source": [
        "strage_name = \"RFR_{}\".format(dateflag)\n",
        "overfit, overstudy = train(\n",
        "    \"{}{}_overfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_RF(X_train, X_train, Y_train, Y_train, task=\"regressor\"),\n",
        ")\n",
        "bestfit, beststudy = train(\n",
        "    \"{}{}_bestfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_RF(X_tra, X_val, Y_tra, Y_val, task=\"regressor\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3Earqplm3rF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = overstudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I427jWwOm4qZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = beststudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4GTA4R69-8y"
      },
      "outputs": [],
      "source": [
        "print(overfit.best_estimator_)\n",
        "depict.regression_metrics(overfit.best_estimator_, X_test, Y_test)\n",
        "print(bestfit.best_estimator_)\n",
        "depict.regression_metrics(bestfit.best_estimator_, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBJERxWO-DFP"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4hQaDWv-FIY"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9h_BdVBbOpRg"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnHHPYVEOr1q"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj2u70uthboO"
      },
      "source": [
        "# Random Forest (classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p5lZhb7hbTL"
      },
      "outputs": [],
      "source": [
        "strage_name = \"RFC_{}\".format(dateflag)\n",
        "overfit, overstudy = train(\n",
        "    \"{}{}_overfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_RF(X_train, X_train, Y2_train, Y2_train, task=\"classifier\"),\n",
        ")\n",
        "bestfit, beststudy = train(\n",
        "    \"{}{}_bestfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_RF(X_tra, X_val, Y2_tra, Y2_val, task=\"classifier\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxomAZ9unnXU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = overstudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u0OO8kTno18"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = beststudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLF5FodRhbQg"
      },
      "outputs": [],
      "source": [
        "print(overfit.best_estimator_)\n",
        "depict.classification_metrics(overfit.best_estimator_, X_test, Y2_test)\n",
        "print(bestfit.best_estimator_)\n",
        "depict.classification_metrics(bestfit.best_estimator_, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN3YEZhbhbMI"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siwJKfaEhbIJ"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCkW4HqFP-0d"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2_eHoaQQCyq"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlPbQRKlj2mR"
      },
      "source": [
        "# Extra Trees (regressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwTg3xbw-HYa"
      },
      "outputs": [],
      "source": [
        "strage_name = \"ETR_{}\".format(dateflag)\n",
        "overfit, overstudy = train(\n",
        "    \"{}{}_overfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_ET(X_train, X_train, Y_train, Y_train, task=\"regressor\"),\n",
        ")\n",
        "bestfit, beststudy = train(\n",
        "    \"{}{}_bestfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_ET(X_tra, X_val, Y_tra, Y_val, task=\"regressor\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gi6LrFc6oRE3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = overstudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpiqZ8kvoR9R"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = beststudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iTPZRmDFhz-"
      },
      "outputs": [],
      "source": [
        "print(overfit.best_estimator_)\n",
        "depict.regression_metrics(overfit.best_estimator_, X_test, Y_test)\n",
        "print(bestfit.best_estimator_)\n",
        "depict.regression_metrics(bestfit.best_estimator_, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwsdTnK7Fj9q"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XgOw_L4FlIw"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAr_TgP0VlaP"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m03h1eZVoSU"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSfDpob8pAfV"
      },
      "source": [
        "# Extra Trees (classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgSMnq3lpAXS"
      },
      "outputs": [],
      "source": [
        "strage_name = \"ETC_{}\".format(dateflag)\n",
        "overfit, overstudy = train(\n",
        "    \"{}{}_overfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_ET(X_train, X_train, Y2_train, Y2_train, task=\"classifier\"),\n",
        ")\n",
        "bestfit, beststudy = train(\n",
        "    \"{}{}_bestfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_ET(X_tra, X_val, Y2_tra, Y2_val, task=\"classifier\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFDsI4zapFxA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = overstudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gflckfKXpGpx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = beststudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEJAf1EUpATM"
      },
      "outputs": [],
      "source": [
        "print(overfit.best_estimator_)\n",
        "depict.classification_metrics(overfit.best_estimator_, X_test, Y2_test)\n",
        "print(bestfit.best_estimator_)\n",
        "depict.classification_metrics(bestfit.best_estimator_, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StgvtkaNpAQE"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YE_MfZDGpAMq"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j90UTYVsW_wv"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRuVlmOzXFvZ"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "106mNhYQphsu"
      },
      "source": [
        "# Gradient Boosting (regressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuuB1lliFmcX"
      },
      "outputs": [],
      "source": [
        "strage_name = \"GBR_{}\".format(dateflag)\n",
        "overfit, overstudy = train(\n",
        "    \"{}{}_overfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_GB(X_train, X_train, Y_train, Y_train, task=\"regressor\"),\n",
        ")\n",
        "bestfit, beststudy = train(\n",
        "    \"{}{}_bestfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_GB(X_tra, X_val, Y_tra, Y_val, task=\"regressor\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJkDeZNBpUNI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = overstudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAxBLcGTpVtv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = beststudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIvpV3YqFqfM"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "\n",
        "print(overfit.best_estimator_)\n",
        "depict.regression_metrics(overfit.best_estimator_, X_test, Y_test)\n",
        "print(bestfit.best_estimator_)\n",
        "depict.regression_metrics(bestfit.best_estimator_, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctGt_oP7FrcQ"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naTUt0QgFsbA"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3r2xzZUHdZxY"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKwZ_sOVdfgF"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Soh_RJD4q65q"
      },
      "source": [
        "# Gradient Boosting (classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsAcze4zq9jq"
      },
      "outputs": [],
      "source": [
        "strage_name = \"GBC_{}\".format(dateflag)\n",
        "overfit, overstudy = train(\n",
        "    \"{}{}_overfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_GB(X_train, X_train, Y2_train, Y2_train, task=\"classifier\"),\n",
        ")\n",
        "bestfit, beststudy = train(\n",
        "    \"{}{}_bestfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_GB(X_tra, X_val, Y2_tra, Y2_val, task=\"classifier\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pkC1u2QrfOr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = overstudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W9PlPgergab"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = beststudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXnnLUhavWIM"
      },
      "outputs": [],
      "source": [
        "print(overfit.best_estimator_)\n",
        "depict.classification_metrics(overfit.best_estimator_, X_test, Y2_test)\n",
        "print(bestfit.best_estimator_)\n",
        "depict.classification_metrics(bestfit.best_estimator_, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQyRrObQvWDg"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH9QUuK5vV_0"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQgpUrEpeGyS"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upe4RMnseIkj"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ghqPFrgviz-"
      },
      "source": [
        "# Multi-Layer Perceptron (regressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_CcMdUdFtpQ"
      },
      "outputs": [],
      "source": [
        "strage_name = \"MLPR_{}\".format(dateflag)\n",
        "overfit, overstudy = train(\n",
        "    \"{}{}_overfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_MLP(X_train, X_train, Y_train, Y_train, task=\"regressor\"),\n",
        ")\n",
        "bestfit, beststudy = train(\n",
        "    \"{}{}_bestfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_MLP(X_tra, X_val, Y_tra, Y_val, task=\"regressor\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3YOSIsAuZzp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = overstudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOaCsrZFuals"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = beststudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4kBtXY5Fxgu"
      },
      "outputs": [],
      "source": [
        "print(overfit.best_estimator_)\n",
        "depict.regression_metrics(overfit.best_estimator_, X_test, Y_test)\n",
        "print(bestfit.best_estimator_)\n",
        "depict.regression_metrics(bestfit.best_estimator_, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xevr4ZS8Fyt4"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2djhpzJGF0BA"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DGTQXtJtTl0"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHD7RjdCtW6Y"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyK8YjA55-To"
      },
      "source": [
        "# Multi-Layer Perceptron (classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ccsYK2jF0z5"
      },
      "outputs": [],
      "source": [
        "strage_name = \"MLPC_{}\".format(dateflag)\n",
        "overfit, overstudy = train(\n",
        "    \"{}{}_overfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_MLP(X_train, X_train, Y2_train, Y2_train, task=\"classifier\"),\n",
        ")\n",
        "bestfit, beststudy = train(\n",
        "    \"{}{}_bestfit\".format(MODEL_PATH, strage_name),\n",
        "    tune_MLP(X_tra, X_val, Y2_tra, Y2_val, task=\"classifier\"),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBAh_6OWyWxU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = overstudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-bgoCLYyX41"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "study = beststudy\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 6))\n",
        "axes[0].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[0] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[1].scatter(\n",
        "    [trial.number for trial in study.trials if trial.values is not None],\n",
        "    [trial.values[1] for trial in study.trials if trial.values is not None],\n",
        "    alpha=0.4,\n",
        ")\n",
        "axes[0].grid()\n",
        "axes[1].grid()\n",
        "axes[0].set_ylabel(\"score\")\n",
        "axes[1].set_ylabel(\"time\")\n",
        "axes[1].set_xlabel(\"trial\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukOhV88E6I_g"
      },
      "outputs": [],
      "source": [
        "from rdkit_supporter import depict\n",
        "\n",
        "print(overfit.best_estimator_)\n",
        "depict.classification_metrics(overfit.best_estimator_, X_test, Y2_test)\n",
        "print(bestfit.best_estimator_)\n",
        "depict.classification_metrics(bestfit.best_estimator_, X_test, Y2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUopQErN6M3U"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsJelzJ_6Oq9"
      },
      "outputs": [],
      "source": [
        "study = overstudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwK-kT8A6Q06"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[0],\n",
        "    target_name=\"score\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvwSbrg7tl0R"
      },
      "outputs": [],
      "source": [
        "study = beststudy\n",
        "fig = optuna.visualization.plot_slice(\n",
        "    study,\n",
        "    params=list(study.trials[0].params.keys()),\n",
        "    target=lambda t: t.values[1],\n",
        "    target_name=\"time\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZSAAP5ptolN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}