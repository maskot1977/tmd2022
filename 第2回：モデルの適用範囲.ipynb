{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maskot1977/tmd2022/blob/JjYuuNRj8Fef/%E7%AC%AC2%E5%9B%9E%EF%BC%9A%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AE%E9%81%A9%E7%94%A8%E7%AF%84%E5%9B%B2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KevDq8UQ6Nl6"
      },
      "source": [
        "「AI創薬・ケモインフォマティクス入門」講義資料　（講師：小寺正明）\n",
        "\n",
        "1月28日（土）19:40～21:10 第2回「モデルの適用範囲」\n",
        "\n",
        "# 第2回：モデルの適用範囲\n",
        "\n",
        "## 各種設定\n",
        "\n",
        "### Google Drive に学習履歴を保存するための設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5g7zQH1U_L6X"
      },
      "outputs": [],
      "source": [
        "# 以下の２つの設定は必要に応じて適宜調整してください。\n",
        "dateflag = \"0117\"  # 解析日を記録するための変数\n",
        "MODEL_PATH = \"./drive/MyDrive/tmd2022-2/\"  # データの保存場所を指定するための変数\n",
        "learning_time_limit = 600  # １つの学習器あたりに許す最大の学習時間（秒）\n",
        "timeout_optuna = 600  # Optuna による反復計算に許す最大の学習時間（秒）\n",
        "n_trials_optuna = 2  # Optuna による反復計算の最大回数（普通は100や1000などの数字を入れる）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYDOVMvelb8L"
      },
      "outputs": [],
      "source": [
        "# Google Colaboratory から Google Drive にマウント\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7HkOFC2lpuG"
      },
      "outputs": [],
      "source": [
        "# もしデータ保存場所がなければ作る\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    os.makedirs(MODEL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVZ2pFHV7mwU"
      },
      "source": [
        "### Optuna のインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c85rLgqq_jtE"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWOKkTfjJnxI"
      },
      "source": [
        "## １次元データ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHyGZzARi5v9"
      },
      "outputs": [],
      "source": [
        "# 二峰性の乱数\n",
        "import numpy as np\n",
        "\n",
        "X = np.sort(\n",
        "    np.concatenate(\n",
        "        [np.random.normal(25, 10, (10, 1)), np.random.normal(75, 10, (20, 1))]\n",
        "    ).flatten()\n",
        ").reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTK3P6SVjD26"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhDWeAsUjTpI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(X)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91ebah0ljcBw"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X, [-0.5 for x in X], alpha=0.5)\n",
        "plt.hist(X)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Y1xHCdIvYq"
      },
      "source": [
        "## K近傍法（k-NearestNeighbors, k-NN）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MH5eMtZqjgUj"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "n_neighbors = 3  # 自分自身を含めて k 番目に近い点までを「近傍」とみなす\n",
        "model = NearestNeighbors(n_neighbors=n_neighbors)  # モデルの立ち上げ\n",
        "model.fit(X)  # X のデータ構造を学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsYH__xPjmDQ"
      },
      "outputs": [],
      "source": [
        "distances, indices = model.kneighbors(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGdGMtlWjuWF"
      },
      "outputs": [],
      "source": [
        "indices  # 自分自身を含む「近隣」インデックスを、自分自身から近い順に"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zp5281xMjoPP"
      },
      "outputs": [],
      "source": [
        "distances  # 「近隣」までの距離"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZrvLfvOjyC4"
      },
      "outputs": [],
      "source": [
        "distances[:, n_neighbors - 1]  # n_neighbors 番目の近隣までの距離"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "METO1u43j3De"
      },
      "outputs": [],
      "source": [
        "sorted(distances[:, n_neighbors - 1])  # n_neighbors 番目の近隣までの距離の小さい順にソート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKqSQtVDj49B"
      },
      "outputs": [],
      "source": [
        "out = 0.1\n",
        "int((len(X) - 1) * (1 - out))  # out の割合を除外したい時の区切りは何番目か"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-uDTijvj8Sj"
      },
      "outputs": [],
      "source": [
        "out = 0.1\n",
        "threshold = sorted(distances[:, n_neighbors - 1])[int((len(X) - 1) * (1 - out))]\n",
        "threshold  # out の割合を除外したい時の閾値はいくらか"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54LOb6pRkW1X"
      },
      "outputs": [],
      "source": [
        "# 閾値より下が「適用範囲」\n",
        "x_latent = np.linspace(0, 100, 101).reshape(-1, 1)\n",
        "plt.plot(\n",
        "    x_latent,\n",
        "    model.kneighbors(x_latent)[0][:, n_neighbors - 1],\n",
        "    label=\"k neighbor distance\",\n",
        ")\n",
        "plt.plot([0, 100], [threshold, threshold], label=\"threshold\")\n",
        "plt.scatter(X, [-0.5 for x in X], alpha=0.5, label=\"data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeiBaTtYTST6"
      },
      "source": [
        "### One Class SVM (OCSVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucl3jmxhkeHI"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "model = OneClassSVM()  # モデルの立ち上げ\n",
        "model.fit(X)  # X のデータ構造を学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwlZCb15khyJ"
      },
      "outputs": [],
      "source": [
        "# 大きいほど、データ密度が高い\n",
        "score = model.decision_function(X)\n",
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8auoy6xk6_H"
      },
      "outputs": [],
      "source": [
        "out = 0.2\n",
        "threshold = sorted(score)[int((len(X) - 1) * out)]\n",
        "threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH9TL9dWk_jS"
      },
      "outputs": [],
      "source": [
        "# 閾値より上が「適用範囲」\n",
        "x_latent = np.linspace(0, 100, 101).reshape(-1, 1)\n",
        "plt.plot(x_latent, model.decision_function(x_latent))\n",
        "plt.plot([0, 100], [threshold, threshold])\n",
        "plt.scatter(X, [1 for x in X], alpha=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgm_Xz_djbhP"
      },
      "source": [
        "## ２次元データ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaZMMr-3k8f5"
      },
      "outputs": [],
      "source": [
        "# ４種類の２次元サンプリングデータを用意します\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "X1 = []  # dense サンプリングデータ\n",
        "for x in np.linspace(-7, 7, 19):\n",
        "    for y in np.linspace(-7, 7, 19):\n",
        "        X1.append([x, y])\n",
        "X1 = np.array(X1)\n",
        "\n",
        "X2 = []  # sparse サンプリングデータ\n",
        "for x in np.linspace(-7, 7, 7):\n",
        "    for y in np.linspace(-7, 7, 7):\n",
        "        X2.append([x, y])\n",
        "X2 = np.array(X2)\n",
        "\n",
        "X3 = []  # O-shape サンプリングデータ\n",
        "for x in np.linspace(-7, 7, 18):\n",
        "    for y in np.linspace(-7, 7, 18):\n",
        "        r = np.sqrt(x ** 2 + y ** 2)\n",
        "        if 4 < r and r < 6:\n",
        "            X3.append([x, y])\n",
        "X3 = np.array(X3)\n",
        "\n",
        "X4 = []  # X-shape サンプリングデータ\n",
        "for x in np.linspace(-7, 7, 19):\n",
        "    for y in np.linspace(-7, 7, 19):\n",
        "        r = np.abs(np.abs(x) - np.abs(y))\n",
        "        if r < 1.5:\n",
        "            X4.append([x, y])\n",
        "X4 = np.array(X4)\n",
        "\n",
        "# サンプリングデータの図示\n",
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(16, 4))\n",
        "for i, X in enumerate([X1, X2, X3, X4]):\n",
        "    axes[i].scatter(X[:, 0], X[:, 1], label=\"X\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmo428G8Ik_I"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# ２次元関数をヒートマップにする関数\n",
        "def heatmap(\n",
        "    f,\n",
        "    x_min=-10,\n",
        "    x_max=10,\n",
        "    y_min=-10,\n",
        "    y_max=10,\n",
        "    h=0.1,\n",
        "    dtype=[0, 1, 1, 1],\n",
        "    epsilon=None,\n",
        "    drawline=False,\n",
        "    cmap=plt.cm.jet,\n",
        "    ax=None,\n",
        "):\n",
        "    def get_Z(f, dt):\n",
        "        if dt == 1:\n",
        "            X = []\n",
        "            for y in np.arange(y_min, y_max, h):\n",
        "                for x in np.arange(x_min, x_max, h):\n",
        "                    X.append([x, y])\n",
        "            X = np.array(X)\n",
        "            Z = f(X).reshape(\n",
        "                len(np.arange(x_min, x_max, h)), len(np.arange(y_min, y_max, h))\n",
        "            )\n",
        "        else:\n",
        "            Z = [[f([x, y]) for x, y in zip(xx, yy)] for xx, yy in zip(x_mg, y_mg)]\n",
        "        return Z\n",
        "\n",
        "    x_mg, y_mg = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    if type(f) == list:\n",
        "        for i, ff in enumerate(f):\n",
        "            if dtype[i] == -1:\n",
        "                if ax is not None:\n",
        "                    pass  # ax.set_contour(x_mg, y_mg, get_Z(ff, 1), colors='black')\n",
        "                else:\n",
        "                    plt.contour(x_mg, y_mg, get_Z(ff, 1), colors=\"black\")\n",
        "            elif i == 0:\n",
        "                Z = np.array(get_Z(ff, dtype[i]))\n",
        "            else:\n",
        "                Z -= np.array(get_Z(ff, dtype[i]))\n",
        "        Z = Z.tolist()\n",
        "\n",
        "    else:\n",
        "        Z = get_Z(f, dtype[0])\n",
        "\n",
        "    if epsilon:\n",
        "        Z = np.array(Z)\n",
        "        Z = np.ma.array(Z, mask=np.abs(Z) <= epsilon)\n",
        "        cmap.set_bad((1, 1, 1, 1))  # 無効な値に対応する色\n",
        "        # cmap.set_bad((0, 0, 0, 1))  # 無効な値に対応する色\n",
        "\n",
        "    if ax is not None:\n",
        "        # ax.set_aspect('equal')\n",
        "        if drawline:\n",
        "            ax.set_contour(x_mg, y_mg, Z, colors=\"black\")\n",
        "        ax.imshow(Z, origin=\"lower\", extent=[x_min, x_max, y_min, y_max], cmap=cmap)\n",
        "        # ax.set_colorbar()\n",
        "        # plt.grid()\n",
        "        # plt.show()\n",
        "    else:\n",
        "        plt.axes().set_aspect(\"equal\")\n",
        "        if drawline:\n",
        "            plt.contour(x_mg, y_mg, Z, colors=\"black\")\n",
        "        plt.imshow(Z, origin=\"lower\", extent=[x_min, x_max, y_min, y_max], cmap=cmap)\n",
        "        plt.colorbar()\n",
        "        # plt.grid()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0Sq480JKBzr"
      },
      "outputs": [],
      "source": [
        "# データ密度を計算するためのクラス\n",
        "\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor, NearestNeighbors\n",
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "\n",
        "class KNN:\n",
        "    def __init__(self, n_neighbors=5, outlier_fraction=0.1, algorithm=\"ball_tree\"):\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.outlier_fraction = outlier_fraction\n",
        "        self.model = False\n",
        "        self.algorithm = algorithm\n",
        "        self.distances = False\n",
        "        self.indices = False\n",
        "        self.threshold = False\n",
        "        self.len_data = False\n",
        "\n",
        "    def fit(self, X):\n",
        "        self.len_data = len(X)\n",
        "        self.model = NearestNeighbors(\n",
        "            n_neighbors=self.n_neighbors, algorithm=self.algorithm\n",
        "        ).fit(X)\n",
        "        self.distances, self.indices = self.model.kneighbors(X)\n",
        "        self.threshold = sorted(self.distances[:, self.n_neighbors - 1])[\n",
        "            int((self.len_data - 1) * (1 - self.outlier_fraction))\n",
        "        ]\n",
        "\n",
        "    def transform(self, x):\n",
        "        self.distances, self.indices = self.model.kneighbors(x)\n",
        "        return self.distances[:, self.n_neighbors - 1]\n",
        "\n",
        "    def transform_bin(self, x):\n",
        "        self.transform(x)\n",
        "        self.Z = self.distances[:, self.n_neighbors - 1]\n",
        "        return np.where(self.Z >= self.threshold, 0, 1)\n",
        "\n",
        "\n",
        "class AVDetector:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model=OneClassSVM(),\n",
        "        outlier_fraction=0.1,\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.outlier_fraction = outlier_fraction\n",
        "        self.threshold = False\n",
        "        self.len_data = False\n",
        "\n",
        "    def fit(self, X):\n",
        "        self.len_data = len(X)\n",
        "        self.model.fit(X)\n",
        "        self.threshold = sorted(self.model.decision_function(X))[\n",
        "            int((self.len_data - 1) * self.outlier_fraction)\n",
        "        ]\n",
        "\n",
        "    def transform(self, x):\n",
        "        return self.model.decision_function(x)\n",
        "\n",
        "    def transform_bin(self, x):\n",
        "        self.Z = self.model.decision_function(x)\n",
        "        return np.where(self.Z >= self.threshold, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBaRoaMNLnSQ"
      },
      "outputs": [],
      "source": [
        "# ４種類のサンプリングデータに５種類のデータ密度計算法を適用して図示\n",
        "\n",
        "avd_dict = {}\n",
        "fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(16, 20))\n",
        "for i, X in enumerate([X1, X2, X3, X4]):\n",
        "    for j, (avd_name, avd) in enumerate(\n",
        "        [\n",
        "            [\"KNN\", KNN()],\n",
        "            [\"OneClassSVM\", AVDetector(model=OneClassSVM())],\n",
        "            [\"IsolationForest\", AVDetector(model=IsolationForest())],\n",
        "            [\"LocalOutlierFactor\", AVDetector(model=LocalOutlierFactor(novelty=True))],\n",
        "            [\"EllipticEnvelope\", AVDetector(model=EllipticEnvelope())],\n",
        "        ]\n",
        "    ):\n",
        "        avd.fit(X)\n",
        "        avd_dict[avd_name] = avd\n",
        "        axes[j][i].set_title(avd_name)\n",
        "        axes[j][i].scatter(X[:, 0], X[:, 1], alpha=0.2)\n",
        "        heatmap([avd.transform, avd.transform_bin], dtype=[1, -1], ax=axes[j][i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDee0ppqPE2r"
      },
      "source": [
        "## 真の関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGcCMkn5J5gM"
      },
      "outputs": [],
      "source": [
        "# 機械学習で予測したい「真の関数」を４種類\n",
        "\n",
        "f1 = (\n",
        "    lambda x: (\n",
        "        np.sqrt(\n",
        "            np.abs(\n",
        "                np.sqrt(\n",
        "                    np.abs(\n",
        "                        np.minimum(\n",
        "                            (x[0] / 3) ** 2 + (x[1] / 3) ** 2 - 1,\n",
        "                            (np.abs(x[0] / 3) - 0.95) ** 2\n",
        "                            + (x[1] / 3 - 0.95) ** 2\n",
        "                            - 0.55 ** 2,\n",
        "                        )\n",
        "                    )\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "        + 1.2 / (1 + np.abs(x[0] ** 2 + (0.8 + x[1]) ** 2))\n",
        "        - 0.8 / (1 + np.abs((1.1 + x[0]) ** 2 + (0.9 - 0.9 * x[1]) ** 2))\n",
        "        - 0.8 / (1 + np.abs((1.1 - x[0]) ** 2 + (0.9 - 0.9 * x[1]) ** 2))\n",
        "        - 1\n",
        "    )\n",
        "    / 0.37\n",
        ")\n",
        "f2 = (\n",
        "    lambda x: (np.sqrt(np.abs(x[0] ** 2 + (x[1] - np.sqrt(np.abs(x[0]))) ** 2)) - 5.8)\n",
        "    / 2.4\n",
        ")\n",
        "f3 = (\n",
        "    lambda x: (np.linalg.norm([x[0], x[1]]) - np.cos(6 * np.arctan2(x[0], x[1])) - 114)\n",
        "    / 0.7\n",
        ")\n",
        "f4 = lambda x: (np.linalg.norm([x[0], x[1]]) - 2 * np.arctan2(x[0], x[1]) - 114) / 3.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgIdq89BjhUB"
      },
      "outputs": [],
      "source": [
        "# 「真の関数」を図示\n",
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(16, 4))\n",
        "axes[0].set_title(\"f1\")\n",
        "heatmap(f1, ax=axes[0])\n",
        "axes[1].set_title(\"f2\")\n",
        "heatmap(f2, ax=axes[1])\n",
        "axes[2].set_title(\"f3\")\n",
        "heatmap(f3, ax=axes[2])\n",
        "axes[3].set_title(\"f4\")\n",
        "heatmap(f4, ax=axes[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWvFHi-e9hOP"
      },
      "source": [
        "## デフォルトパラメーターでフィッティング"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbk2d_9bgkDO"
      },
      "outputs": [],
      "source": [
        "# 主要な９種類の機械学習手法で、４種類のサンプリングデータから、４種類の「真の関数」にフィッティング\n",
        "\n",
        "from sklearn.ensemble import (\n",
        "    ExtraTreesRegressor,\n",
        "    HistGradientBoostingRegressor,\n",
        "    RandomForestRegressor,\n",
        ")\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "models = [\n",
        "    [\"LR\", LinearRegression()],\n",
        "    [\"SVM\", SVR()],\n",
        "    [\"KN\", KNeighborsRegressor()],\n",
        "    [\"GP\", GaussianProcessRegressor()],\n",
        "    [\"DT\", DecisionTreeRegressor()],\n",
        "    [\"RF\", RandomForestRegressor()],\n",
        "    [\"ET\", ExtraTreesRegressor()],\n",
        "    [\"GB\", HistGradientBoostingRegressor()],\n",
        "    [\"MLP\", MLPRegressor()],\n",
        "]\n",
        "\n",
        "obtained_models = {}\n",
        "for data_name, X in [[\"dense\", X1], [\"sparse\", X2], [\"O-shape\", X3], [\"X-shape\", X4]]:\n",
        "    fig, axes = plt.subplots(\n",
        "        nrows=len(models) + 1, ncols=4, figsize=(16, 4 * len(models) + 1)\n",
        "    )\n",
        "    for i, f in enumerate([f1, f2, f3, f4]):\n",
        "        axes[0][i].set_title(\"{} f_{}\".format(data_name, i + 1))\n",
        "        axes[0][i].scatter(X[:, 0], X[:, 1], alpha=0.1)\n",
        "        axes[0][i].xaxis.set_visible(False)\n",
        "        axes[0][i].yaxis.set_visible(False)\n",
        "        heatmap(f, ax=axes[0][i])\n",
        "        for j, (model_name, model) in enumerate(models):\n",
        "            model.fit(X, f(X.T))\n",
        "            axes[j + 1][i].set_title(\"{} f_{}, {}\".format(data_name, i + 1, model_name))\n",
        "            axes[j + 1][i].xaxis.set_visible(False)\n",
        "            axes[j + 1][i].yaxis.set_visible(False)\n",
        "            heatmap(model.predict, dtype=[1], ax=axes[j + 1][i])\n",
        "            obtained_models[(data_name, i, j)] = model\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20Aj5upL-Vdd"
      },
      "source": [
        "## Optuna によるハイパーパラメーターチューニング"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0kNhYeBYaws"
      },
      "outputs": [],
      "source": [
        "from functools import wraps\n",
        "\n",
        "\n",
        "# 学習に時間がかかりすぎる場合に強制終了するための方法\n",
        "def on_timeout(limit, handler, hint=None):\n",
        "    def notify_handler(signum, frame):\n",
        "        handler(\n",
        "            \"'%s' terminated since it did not finish in %d seconds.\" % (hint, limit)\n",
        "        )\n",
        "\n",
        "    def __decorator(function):\n",
        "        def __wrapper(*args, **kwargs):\n",
        "            import signal\n",
        "\n",
        "            signal.signal(signal.SIGALRM, notify_handler)\n",
        "            signal.alarm(limit)\n",
        "            result = function(*args, **kwargs)\n",
        "            signal.alarm(0)\n",
        "            return result\n",
        "\n",
        "        return wraps(function)(__wrapper)\n",
        "\n",
        "    return __decorator\n",
        "\n",
        "\n",
        "def handler_func(msg):\n",
        "    print(msg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdLUAmpzqq-i"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "\n",
        "# Optunaでチューニングするための基本クラス\n",
        "class BestTune:\n",
        "    def __init__(self, x_train, x_valid, t_train, t_valid):\n",
        "        # 訓練データを格納\n",
        "        self.x_train = x_train\n",
        "        self.t_train = t_train\n",
        "\n",
        "        # 検証データを格納\n",
        "        self.x_valid = x_valid\n",
        "        self.t_valid = t_valid\n",
        "\n",
        "        # ベストモデルとスコアを格納\n",
        "        self.best_score = None\n",
        "        self.best_model = None\n",
        "\n",
        "    def get_model_params(self, trial):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_base_model(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @on_timeout(limit=learning_time_limit, handler=handler_func, hint=u\"BestTune\")\n",
        "    def __call__(self, trial):\n",
        "        model_params = self.get_model_params(trial)\n",
        "        model = self.get_base_model()(**model_params)\n",
        "        model.fit(self.x_train, self.t_train)\n",
        "\n",
        "        # 検証データの予測性能を評価\n",
        "        score = mean_absolute_error(model.predict(self.x_valid), self.t_valid)\n",
        "\n",
        "        # ベストスコアが出れば、そのベストモデルを記録\n",
        "        if self.best_model is None or self.best_score > score:\n",
        "            self.best_score = score\n",
        "            self.best_model = copy.deepcopy(model)\n",
        "\n",
        "        # スコアを返す\n",
        "        return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yT4fu0hAyKtd"
      },
      "outputs": [],
      "source": [
        "# Support Vector Machine Regressor\n",
        "class best_SVR(BestTune):\n",
        "    def get_base_model(self):\n",
        "        return SVR\n",
        "\n",
        "    def get_model_params(self, trial):\n",
        "        # チューニングしたいパラメータの範囲を設定\n",
        "        model_params = {}\n",
        "        model_params[\"C\"] = trial.suggest_float(\"C\", 1e-10, 1e10, log=True)\n",
        "        model_params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-10, 1e10, log=True)\n",
        "        model_params[\"epsilon\"] = trial.suggest_float(\"epsilon\", 1e-10, 1e10, log=True)\n",
        "        model_params[\"max_iter\"] = 530000\n",
        "        return model_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCpwpNvSqTPQ"
      },
      "outputs": [],
      "source": [
        "# K-Neighbors Regressor\n",
        "class best_KN(BestTune):\n",
        "    def get_base_model(self):\n",
        "        return KNeighborsRegressor\n",
        "\n",
        "    def get_model_params(self, trial):\n",
        "        model_params = {}\n",
        "        model_params[\"algorithm\"] = trial.suggest_categorical(\n",
        "            \"algorithm\", [\"ball_tree\", \"kd_tree\", \"brute\"]\n",
        "        )\n",
        "        model_params[\"n_neighbors\"] = trial.suggest_int(\"n_neighbors\", 1, 10)\n",
        "        model_params[\"weights\"] = trial.suggest_categorical(\n",
        "            \"weights\", [\"uniform\", \"distance\"]\n",
        "        )\n",
        "        return model_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL31Wl0T9zqD"
      },
      "outputs": [],
      "source": [
        "# Decision Tree Regressor\n",
        "class best_DT(BestTune):\n",
        "    def get_base_model(self):\n",
        "        return DecisionTreeRegressor\n",
        "\n",
        "    def get_model_params(self, trial):\n",
        "        model_params = {}\n",
        "        model_params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 10)\n",
        "        model_params[\"min_samples_leaf\"] = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
        "        model_params[\"criterion\"] = trial.suggest_categorical(\n",
        "            \"criterion\", [\"squared_error\", \"friedman_mse\", \"absolute_error\"]\n",
        "        )\n",
        "        return model_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtmJ0LD2KSjz"
      },
      "outputs": [],
      "source": [
        "# Random Forest Regressor\n",
        "class best_RF(BestTune):\n",
        "    def get_base_model(self):\n",
        "        return RandomForestRegressor\n",
        "\n",
        "    def get_model_params(self, trial):\n",
        "        model_params = {}\n",
        "        model_params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 10)\n",
        "        model_params[\"min_samples_leaf\"] = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
        "        model_params[\"criterion\"] = trial.suggest_categorical(\n",
        "            \"criterion\", [\"squared_error\", \"friedman_mse\", \"absolute_error\"]\n",
        "        )\n",
        "        return model_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFo9ZK8dKcLI"
      },
      "outputs": [],
      "source": [
        "# ExtraTrees Regressor\n",
        "class best_ET(BestTune):\n",
        "    def get_base_model(self):\n",
        "        return ExtraTreesRegressor\n",
        "\n",
        "    def get_model_params(self, trial):\n",
        "        model_params = {}\n",
        "        model_params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 10)\n",
        "        model_params[\"min_samples_leaf\"] = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
        "        model_params[\"criterion\"] = trial.suggest_categorical(\n",
        "            \"criterion\", [\"squared_error\", \"friedman_mse\", \"absolute_error\"]\n",
        "        )\n",
        "        return model_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIdiH4wVKi4A"
      },
      "outputs": [],
      "source": [
        "# GradientBoosting Regressor\n",
        "class best_GB(BestTune):\n",
        "    def get_base_model(self):\n",
        "        return HistGradientBoostingRegressor\n",
        "\n",
        "    def get_model_params(self, trial):\n",
        "        model_params = {}\n",
        "        model_params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 10)\n",
        "        model_params[\"min_samples_leaf\"] = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
        "        model_params[\"loss\"] = trial.suggest_categorical(\n",
        "            \"loss\", [\"squared_error\", \"absolute_error\"]\n",
        "        )\n",
        "        return model_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5M5X56KwKq-N"
      },
      "outputs": [],
      "source": [
        "# Multi-Layer Perceptron Regressor\n",
        "class best_MLP(BestTune):\n",
        "    def get_base_model(self):\n",
        "        return MLPRegressor\n",
        "\n",
        "    def get_model_params(self, trial):\n",
        "        model_params = {}\n",
        "        n_layer = trial.suggest_int(\"n_layer\", 1, 10)\n",
        "        in_neuron = trial.suggest_int(\"in_neuron\", 1, 200)\n",
        "        mid_neuron = trial.suggest_int(\"mid_neuron\", 1, 200)\n",
        "        out_neuron = trial.suggest_int(\"out_neuron\", 1, 200)\n",
        "        model_params[\"hidden_layer_sizes\"] = (\n",
        "            [in_neuron] + [mid_neuron] * n_layer + [out_neuron]\n",
        "        )\n",
        "        model_params[\"activation\"] = trial.suggest_categorical(\n",
        "            \"activation\", [\"logistic\", \"tanh\", \"relu\"]\n",
        "        )\n",
        "        model_params[\"learning_rate\"] = trial.suggest_categorical(\n",
        "            \"learning_rate\", [\"constant\", \"invscaling\", \"adaptive\"]\n",
        "        )\n",
        "        # model_params[\"solver\"] = trial.suggest_categorical(\n",
        "        #    \"solver\", [\"lbfgs\", \"adam\"]\n",
        "        # )\n",
        "        model_params[\"early_stopping\"] = trial.suggest_categorical(\n",
        "            \"early_stopping\", [True, False]\n",
        "        )\n",
        "        model_params[\"max_iter\"] = 530000\n",
        "        return model_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OoQN3PJemS_"
      },
      "outputs": [],
      "source": [
        "# 偶数番目のデータを教師データ、奇数番目のデータを検証データとする\n",
        "\n",
        "\n",
        "def train_test_split(X):\n",
        "    index = np.arange(X.shape[0])\n",
        "    train_index = index[index % 2 == 0]\n",
        "    test_index = index[index % 2 != 0]\n",
        "    X_train = X[train_index, :]\n",
        "    X_test = X[test_index, :]\n",
        "    return X_train, X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuPW7nEnn_H_"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "\n",
        "# Optuna で学習を繰り返し、学習履歴を保存する\n",
        "def train(\n",
        "    study_name,\n",
        "    f,\n",
        "    tune_model,\n",
        "    X_train,\n",
        "    X_test,\n",
        "    timeout=timeout_optuna,\n",
        "    n_trials=n_trials_optuna,\n",
        "    show_progress_bar=True,\n",
        "):\n",
        "    import warnings\n",
        "\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    optuna.logging.set_verbosity(optuna.logging.WARN)\n",
        "    best_model = tune_model(X_train, X_test, f(X_train.T), f(X_test.T))\n",
        "\n",
        "    # 学習環境を立ち上げる\n",
        "    study = optuna.create_study(\n",
        "        study_name=study_name,\n",
        "        storage=\"sqlite:///\" + study_name + \".sql\",\n",
        "        load_if_exists=True,\n",
        "        direction=\"minimize\",\n",
        "    )\n",
        "    try:\n",
        "        study.enqueue_trial(study.best_trial.params)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # 学習する\n",
        "    study.optimize(\n",
        "        best_model,\n",
        "        timeout=timeout,\n",
        "        n_trials=n_trials,\n",
        "        show_progress_bar=show_progress_bar,\n",
        "    )\n",
        "    return best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNqbL5zItxTK"
      },
      "outputs": [],
      "source": [
        "# ７種類の機械学習手法で、４種類のサンプリングデータから、４種類の「真の関数」を学習\n",
        "for data_name, X in [\n",
        "    [\"O-shape\", X3],\n",
        "    [\"X-shape\", X4],\n",
        "    [\"dense\", X1],\n",
        "    [\"sparse\", X2],\n",
        "]:\n",
        "    for func_name, f in [[\"f1\", f1], [\"f2\", f2], [\"f3\", f3], [\"f4\", f4]]:\n",
        "        for model_name, tune_model in [\n",
        "            [\"SVM\", best_SVR],\n",
        "            [\"KN\", best_KN],\n",
        "            [\"DT\", best_DT],\n",
        "            [\"RF\", best_RF],\n",
        "            [\"ET\", best_ET],\n",
        "            [\"GB\", best_GB],\n",
        "            [\"MLP\", best_MLP],\n",
        "        ]:\n",
        "            strage_name = \"_\".join([model_name, func_name, data_name, dateflag])\n",
        "            X_train, X_test = train_test_split(X)\n",
        "            overfit = train(\n",
        "                \"{}{}_overfit\".format(MODEL_PATH, strage_name), f, tune_model, X, X\n",
        "            )\n",
        "            bestfit = train(\n",
        "                \"{}{}_bestfit\".format(MODEL_PATH, strage_name),\n",
        "                f,\n",
        "                tune_model,\n",
        "                X_train,\n",
        "                X_test,\n",
        "            )\n",
        "\n",
        "            fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(16, 8))\n",
        "            axes[0][0].set_title(func_name)\n",
        "            axes[1][0].set_title(func_name)\n",
        "            axes[0][1].set_title(\n",
        "                \"_\".join([model_name, func_name, data_name, \"overfit\"])\n",
        "            )\n",
        "            axes[0][2].set_title(\n",
        "                \"_\".join([model_name, func_name, data_name, \"overfit\", \"diff\"])\n",
        "            )\n",
        "            axes[1][1].set_title(\n",
        "                \"_\".join([model_name, func_name, data_name, \"bestfit\"])\n",
        "            )\n",
        "            axes[1][2].set_title(\n",
        "                \"_\".join([model_name, func_name, data_name, \"bestfit\", \"diff\"])\n",
        "            )\n",
        "            heatmap(f, ax=axes[0][0])\n",
        "            axes[0][0].scatter(X[:, 0], X[:, 1], alpha=0.1)\n",
        "            heatmap(f, ax=axes[1][0])\n",
        "            axes[1][0].scatter(X_train[:, 0], X_train[:, 1], alpha=0.1)\n",
        "            heatmap(overfit.best_model.predict, dtype=[1], ax=axes[0][1])\n",
        "            heatmap(\n",
        "                [f, overfit.best_model.predict],\n",
        "                dtype=[0, 1],\n",
        "                epsilon=0.1,\n",
        "                ax=axes[0][2],\n",
        "            )\n",
        "            heatmap(bestfit.best_model.predict, dtype=[1], ax=axes[1][1])\n",
        "            heatmap(\n",
        "                [f, bestfit.best_model.predict],\n",
        "                dtype=[0, 1],\n",
        "                epsilon=0.1,\n",
        "                ax=axes[1][2],\n",
        "            )\n",
        "            axes[0][3].set_title(\n",
        "                \"MAE={:.4f}\".format(\n",
        "                    mean_absolute_error(f(X.T), overfit.best_model.predict(X))\n",
        "                )\n",
        "            )\n",
        "            axes[0][3].scatter(f(X.T), overfit.best_model.predict(X), alpha=0.5)\n",
        "            axes[1][3].set_title(\n",
        "                \"MAE(train, test)={:.4f}, {:.4f}\".format(\n",
        "                    mean_absolute_error(\n",
        "                        f(X_train.T), bestfit.best_model.predict(X_train)\n",
        "                    ),\n",
        "                    mean_absolute_error(\n",
        "                        f(X_test.T), bestfit.best_model.predict(X_test)\n",
        "                    ),\n",
        "                )\n",
        "            )\n",
        "            axes[1][3].scatter(\n",
        "                f(X_train.T),\n",
        "                bestfit.best_model.predict(X_train),\n",
        "                alpha=0.5,\n",
        "                label=\"train\",\n",
        "            )\n",
        "            axes[1][3].scatter(\n",
        "                f(X_test.T), bestfit.best_model.predict(X_test), alpha=0.5, label=\"test\"\n",
        "            )\n",
        "            axes[1][3].legend()\n",
        "            plt.savefig(\n",
        "                \"{}{}.png\".format(MODEL_PATH, strage_name), format=\"png\", dpi=300\n",
        "            )\n",
        "            plt.show()\n",
        "            print(\"Overfit model=\", overfit.best_model)\n",
        "            print(\"Bestfit model=\", bestfit.best_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfX5IpEa-1ne"
      },
      "source": [
        "## ハイパーパラメーターの解析"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJOhxzn7unGm"
      },
      "outputs": [],
      "source": [
        "# Optunaによる学習履歴を記録することで、ハイパーパラメーターの影響を可視化できます\n",
        "import glob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optuna\n",
        "\n",
        "for file in sorted(glob.glob(MODEL_PATH + \"*fit.sql\")):\n",
        "    print(file)\n",
        "    study = optuna.create_study(\n",
        "        study_name=file.replace(\".sql\", \"\"),\n",
        "        storage=\"sqlite:///\" + file,\n",
        "        load_if_exists=True,\n",
        "        direction=\"minimize\",\n",
        "    )\n",
        "    importances = np.array(\n",
        "        [[k, v] for k, v in optuna.importance.get_param_importances(study).items()]\n",
        "    )\n",
        "    optuna.visualization.plot_param_importances(study).show()\n",
        "    optuna.visualization.plot_contour(\n",
        "        study, params=[importances[0, 0], importances[1, 0]]\n",
        "    ).show()\n",
        "    # break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9xFnu2c3g-s"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}